# ELK: Enhanced Learning through cross-modal Knowledge transfer for lesion detection in limited-sample contrast-enhanced mammography datasets

This is the official PyTorch implementation of the Deep-Brea<sup>3</sup>th-MICCAI 2024 paper 
["ELK: Enhanced Learning through cross-modal Knowledge transfer for lesion detection in limited-sample contrast-enhanced mammography datasets"](none)

## Abstract
This paper introduced ELK, a cross-modal knowledge transfer method to enhance the performance of lesion detection in limited-sampled datasets, such as clinical studies of contrast enhanced mammography, leveraging large cross-domain pretrained models. Our method allows boosting the performance of small datasets in a fast and relatively limited-resourced setting. Future work includes exploring the effect of adding more than one synthetic lesion per healthy image in the generation process, as well as controlling the type of lesion generated by adding text conditioning.


## Repository structure
```
.
├── README.md
├── data
│   ├── CDD-CESM
│   │   ├── images
│   │   ├── masks
│   │   ├── masks_closeup
│   │   └── metadata
│   ├── models
│   │   ├── config_trained_R_101_30k.yaml
│   │   └── model_final_R_101_omidb_30k_dbt9k_f12_gray.pth
│   └── SET-Mex
│       ├── binary_masks
│       ├── images
│       └── metadata
├── data_analysis
├── detection
├── envs
├── generation
├── utils.py
