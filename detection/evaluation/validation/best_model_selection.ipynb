{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add repo path to the system path\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "repo_path= Path.cwd().resolve()\n",
    "while '.gitignore' not in os.listdir(repo_path): # while not in the root of the repo\n",
    "    repo_path = repo_path.parent #go up one level\n",
    "sys.path.insert(0,str(repo_path)) if str(repo_path) not in sys.path else None\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "from detectron2.structures import pairwise_iou, boxes\n",
    "\n",
    "from detection.inference.detector import lesion_detector, post_process_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation phase\n",
    "- In this part we select the best model of each fine-tuned model and we validate it using the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the prediction and FROC information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_single_FROC(froc_info, model_name, FPpI_limit=1.0, fig_ax:tuple=None):\n",
    "    # graph\n",
    "    fig, ax = plt.subplots(figsize=(6,6)) if fig_ax is None else (fig_ax[0], fig_ax[1])\n",
    "    ax.set_xlabel('FPpI')\n",
    "    ax.set_ylabel('TPR')\n",
    "    ax.set_title('FROC curve')\n",
    "    # set TPR limits\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.set_xlim(0,FPpI_limit)\n",
    "\n",
    "    # smooth curve\n",
    "    ax.plot(froc_info['FPpI'], froc_info['TPR'], marker='', label=f'{model_name}', linestyle='-', linewidth=1.5)\n",
    "    ax.legend()\n",
    "\n",
    "def AUFROC_computing(froc_info, FPpI_limit=1.0):\n",
    "    \"\"\"compute the FROC area under the curve.\n",
    "    By thefault the AUC is computed up to 1 FPpI, if the limit is surpassed, the curve is cut at the limit.\n",
    "\n",
    "    Args:\n",
    "        froc_info (_type_): _description_\n",
    "        FPpI_limit (float, optional): _description_. Defaults to 1.0.\n",
    "\n",
    "    Returns:\n",
    "        float: AUC value\n",
    "    \"\"\" \n",
    "    # check if the FPpI limit is reached\n",
    "    if froc_info['FPpI'].max() < FPpI_limit:\n",
    "        # add a point to reach the limit, adding a row\n",
    "        froc_info = pd.concat([froc_info, pd.DataFrame({'FPpI': [FPpI_limit], 'TPR': [froc_info['TPR'].iloc[-1]]})], ignore_index=True)\n",
    "    # check if the FPpI limit is surpassed\n",
    "    elif froc_info['FPpI'].max() > FPpI_limit:\n",
    "        # remove points that surpass the limit\n",
    "        froc_info = froc_info[froc_info['FPpI'] <= FPpI_limit]\n",
    "        # add a point to reach the limit, adding a row\n",
    "        froc_info = pd.concat([froc_info, pd.DataFrame({'FPpI': [FPpI_limit], 'TPR': [froc_info['TPR'].iloc[-1]]})], ignore_index=True)\n",
    "\n",
    "    # compute the area under the curve using the trapezoidal rule\n",
    "    AUC_value = np.trapz(froc_info['TPR'], x=froc_info['FPpI'])\n",
    "\n",
    "    return AUC_value\n",
    "\n",
    "\n",
    "def sensitivity_computation(froc_info):\n",
    "    \"\"\"compute the mean sensitivity at 1/8 , 1/4 and 1/2 FPpI, 1 FPpI and 2 FPpI\n",
    "\n",
    "    Args:\n",
    "        froc_info (pd.DataFrame): dataframe with the FROC info\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with the mean sensitivity at 1/8 , 1/4 and 1/2 FPpI, 1 FPpI and 2 FPpI\n",
    "    \"\"\"\n",
    "    # compute mean sensitivity at 1/8 , 1/4 and 1/2 FPpI, 1 FPpI and 2 FPpI\n",
    "    sensitivities  = []\n",
    "    ranges_to_compute = [1/8, 1/4, 1/2, 1, 2]\n",
    "    for value in ranges_to_compute:\n",
    "        sensitivities.append(froc_info[froc_info['FPpI'] <= value]['TPR'].mean())\n",
    "    # create a dataframe\n",
    "    sensitivity_df = pd.DataFrame({'FPpI': ranges_to_compute, 'sensitivity': sensitivities})\n",
    "    \n",
    "    return sensitivity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model inputs\n",
    "config_file = repo_path / 'detection/training/config_files/fine_tuning_CEM.yaml'\n",
    "min_score = 0.1 # minimum score threshold to keep the prediction\n",
    "\n",
    "## data inputs\n",
    "im_dir = repo_path / 'data/CDD-CESM/images/substracted' # images directory (can contain other not only test)\n",
    "metadata_path = repo_path / 'data/CDD-CESM/metadata/bboxes/split_1/val_set.csv' # val metadata (only val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/synthetic'),\n",
       " PosixPath('/home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/normal_fine-tuning'),\n",
       " PosixPath('/home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/synthetic_improved'),\n",
       " PosixPath('/home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/real-synth_improved'),\n",
       " PosixPath('/home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/real-synth_fine-tuning')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all subfolders\n",
    "dir_ex = repo_path / 'detection/training/results/split_1_old'\n",
    "subfolders = [f for f in dir_ex.iterdir() if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/06 20:38:51 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/real-synth_fine-tuning/model_0004999.pth ...\n",
      "\u001b[32m[03/06 20:38:55 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/real-synth_fine-tuning/model_0009999.pth ...\n",
      "\u001b[32m[03/06 20:39:00 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/real-synth_fine-tuning/model_0014999.pth ...\n",
      "\u001b[32m[03/06 20:39:05 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/real-synth_fine-tuning/model_0019999.pth ...\n",
      "\u001b[32m[03/06 20:39:09 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/real-synth_fine-tuning/model_0024999.pth ...\n",
      "\u001b[32m[03/06 20:39:14 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/ricardo/projects/CEM-Detect/detection/training/results/split_1_old/real-synth_fine-tuning/model_0029999.pth ...\n"
     ]
    }
   ],
   "source": [
    "model_type_dir = Path('detection/training/results/split_1_old/real-synth_fine-tuning')\n",
    "# csv saving with FROC info\n",
    "saving_dir = repo_path / 'detection/evaluation/data/validation' / model_type_dir.parent.name / model_type_dir.name\n",
    "saving_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# collect all possible model steps\n",
    "step_list = list((repo_path / model_type_dir).rglob('*.pth')) # get all files with ending .pth\n",
    "step_list = [x for x in step_list if 'model_final' not in x.name] # remove model_final.pth\n",
    "step_list.sort(key=lambda x: int(x.name.split('_')[-1].split('.')[0]))\n",
    "\n",
    "for model_file in step_list:\n",
    "    \n",
    "    detector = lesion_detector(config_file, model_file, metadata_path, im_dir, min_score)\n",
    "    detector.start_metrics()\n",
    "    for im_name in detector.test_df['image_name'].unique()[0:]:\n",
    "        detector.c_im_name = im_name\n",
    "        detector.prepare_im_gt()\n",
    "        detector.predict()\n",
    "        # detector.show_c_predictions()\n",
    "        # metrics computing\n",
    "        used_preds = detector.compute_TP_FN_counts(show=False)\n",
    "        detector.compute_FP_counts(used_preds)\n",
    "    froc_info  = detector.compute_FROC()\n",
    "    froc_info.to_csv(saving_dir / f'{model_file.stem}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area can be computed using the trapezoidal rule. We only need to define the max FPpI limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROC_info_dir = repo_path / 'detection/evaluation/data/validation' / model_type_dir.parent.name / model_type_dir.name\n",
    "# saving_AUFROCs\n",
    "AUFROC_dir = repo_path / 'detection/evaluation/data/validation'/ model_type_dir.parent.name / 'AUFROCs'\n",
    "# get all csv files\n",
    "csv_files = list(FROC_info_dir.rglob('*.csv'))\n",
    "\n",
    "AUFROC_df = None\n",
    "# example of model curve\n",
    "for csv_path in csv_files:\n",
    "\n",
    "    model_name = csv_path.stem\n",
    "    froc_info = pd.read_csv(csv_path)\n",
    "\n",
    "    # compute metrics\n",
    "    AUFROC_value = AUFROC_computing(froc_info)\n",
    "    # store AUC\n",
    "    AUFROC_df = pd.concat([AUFROC_df, pd.DataFrame({'model_name': [model_name], 'AUFROC': [AUFROC_value]})], ignore_index=True)\n",
    "# save\n",
    "AUFROC_df.to_csv(AUFROC_dir / f'{model_type_dir.name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
