{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add repo path to the system path\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "repo_path= Path.cwd().resolve()\n",
    "while '.gitignore' not in os.listdir(repo_path): # while not in the root of the repo\n",
    "    repo_path = repo_path.parent #go up one level\n",
    "sys.path.insert(0,str(repo_path)) if str(repo_path) not in sys.path else None\n",
    "sys.path.insert(0,str(repo_path / 'detr')) if str(repo_path / 'detr') not in sys.path else None\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.structures import pairwise_iou, boxes\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, launch\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_train_loader\n",
    "from detectron2.solver.build import maybe_add_gradient_clipping\n",
    "\n",
    "from typing import Any, Dict, List, Set\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    Extension of the Trainer class adapted to DETR.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        \"\"\"\n",
    "        Create evaluator(s) for a given dataset.\n",
    "        This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n",
    "        For your own dataset, you can simply create an evaluator manually in your\n",
    "        script and do not have to worry about the hacky if-else logic here.\n",
    "        \"\"\"\n",
    "        if output_folder is None:\n",
    "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=None)\n",
    "\n",
    "    @classmethod\n",
    "    def build_optimizer(cls, cfg, model):\n",
    "        params: List[Dict[str, Any]] = []\n",
    "        memo: Set[torch.nn.parameter.Parameter] = set()\n",
    "        for key, value in model.named_parameters(recurse=True):\n",
    "            if not value.requires_grad:\n",
    "                continue\n",
    "            # Avoid duplicating parameters\n",
    "            if value in memo:\n",
    "                continue\n",
    "            memo.add(value)\n",
    "            lr = cfg.SOLVER.BASE_LR\n",
    "            weight_decay = cfg.SOLVER.WEIGHT_DECAY\n",
    "            if \"backbone\" in key:\n",
    "                lr = lr * cfg.SOLVER.BACKBONE_MULTIPLIER\n",
    "            params += [{\"params\": [value], \"lr\": lr, \"weight_decay\": weight_decay}]\n",
    "\n",
    "        def maybe_add_full_model_gradient_clipping(optim):  # optim: the optimizer class\n",
    "            # detectron2 doesn't have full model gradient clipping now\n",
    "            clip_norm_val = cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE\n",
    "            enable = (\n",
    "                cfg.SOLVER.CLIP_GRADIENTS.ENABLED\n",
    "                and cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE == \"full_model\"\n",
    "                and clip_norm_val > 0.0\n",
    "            )\n",
    "\n",
    "            class FullModelGradientClippingOptimizer(optim):\n",
    "                def step(self, closure=None):\n",
    "                    all_params = itertools.chain(*[x[\"params\"] for x in self.param_groups])\n",
    "                    torch.nn.utils.clip_grad_norm_(all_params, clip_norm_val)\n",
    "                    super().step(closure=closure)\n",
    "\n",
    "            return FullModelGradientClippingOptimizer if enable else optim\n",
    "\n",
    "        optimizer_type = cfg.SOLVER.OPTIMIZER\n",
    "        if optimizer_type == \"SGD\":\n",
    "            optimizer = maybe_add_full_model_gradient_clipping(torch.optim.SGD)(\n",
    "                params, cfg.SOLVER.BASE_LR, momentum=cfg.SOLVER.MOMENTUM\n",
    "            )\n",
    "        elif optimizer_type == \"ADAMW\":\n",
    "            optimizer = maybe_add_full_model_gradient_clipping(torch.optim.AdamW)(\n",
    "                params, cfg.SOLVER.BASE_LR\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError(f\"no optimizer type {optimizer_type}\")\n",
    "        if not cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE == \"full_model\":\n",
    "            optimizer = maybe_add_gradient_clipping(cfg, optimizer)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetCatalog.clear()\n",
    "\n",
    "# parameters\n",
    "iter_CEM = 30000\n",
    "p_CEM = \"30k\"\n",
    "\n",
    "# tests:. 101 vs R2\n",
    "m_layer = 'R_101'\n",
    "g_rgb = \"gray\" # if we train with rgb or grayscale\n",
    "csv_dbt_file= \"../train_bboxes_gray_fold2.csv\"\n",
    "dbt_dicts = \"/home/robert/data/DBT2/train_gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_omidb_dicts(img_dir):\n",
    "    \n",
    "    csv_file = os.path.join(img_dir, \"omidb-selection.csv\")\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    dataset_dicts = []\n",
    "    for idx, row in df.iterrows():\n",
    "        record = {}\n",
    "        skip_file = False\n",
    "        if (row[\"type\"] == 'M'):\n",
    "            filename = os.path.join(img_dir+\"/HOLOGIC/ffdm/st\"+\"{0:03}\".format(row[\"subtype\"]), row[\"filename\"])\n",
    "        if (row[\"type\"] == 'MU'):\n",
    "            filename = os.path.join(img_dir+\"/HOLOGIC/ffdm/stu\", row[\"filename\"])\n",
    "        if (row[\"type\"] == 'B'):\n",
    "            filename = os.path.join(img_dir+\"/HOLOGIC/ffdm/benign\", row[\"filename\"])\n",
    "        if (row[\"type\"] == 'N'):\n",
    "            filename = os.path.join(img_dir+\"/HOLOGIC/ffdm/normal\", row[\"filename\"])\n",
    "#             skip_file = True\n",
    "        \n",
    "        if (not skip_file):\n",
    "\n",
    "            # its slow, reading all the images to know dimensions!         \n",
    "    #         height, width = cv2.imread(filename).shape[:2]\n",
    "\n",
    "            record[\"file_name\"] = filename\n",
    "            record[\"image_id\"] = idx\n",
    "\n",
    "            # Bounding box breast area         \n",
    "            bbox = row[\"bbox\"][12:-1]\n",
    "            coords = bbox.split(',')\n",
    "            r= np.array([0,0,0,0])\n",
    "            idx = 0\n",
    "            for c in coords:\n",
    "                aux = c.split('=')\n",
    "                r[idx]=(int(aux[1]))\n",
    "                idx +=1\n",
    "\n",
    "            # we can get width and heigth from bbox\n",
    "            record[\"height\"] = r[3]-r[1]\n",
    "            record[\"width\"] = r[2]-r[0]\n",
    "\n",
    "            if (row[\"type\"] == 'N'): \n",
    "                record[\"annotations\"] = []\n",
    "            else:\n",
    "                # Bounding box roi  \n",
    "                bbox_roi = row[\"bbox_roi\"][12:-1]\n",
    "                coords = bbox_roi.split(',')\n",
    "                s= np.array([0,0,0,0])\n",
    "                idx = 0\n",
    "                for c in coords:\n",
    "                    aux = c.split('=')\n",
    "                    s[idx]=(int(aux[1]))\n",
    "                    idx +=1\n",
    "                bbox_roi = omidb.mark.BoundingBox(s[0]-r[0],s[1]-r[1],s[2]-r[0],s[3]-r[1])\n",
    "\n",
    "                px = [bbox_roi.x1, bbox_roi.x2, bbox_roi.x2, bbox_roi.x1]\n",
    "                py = [bbox_roi.y1, bbox_roi.y1, bbox_roi.y2, bbox_roi.y2]\n",
    "                poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "                poly = [p for x in poly for p in x]\n",
    "                objs = []\n",
    "                obj =  {\n",
    "                        \"bbox\": [bbox_roi.x1 , bbox_roi.y1, bbox_roi.x2, bbox_roi.y2],\n",
    "                        \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                        \"segmentation\": [poly],\n",
    "                        \"category_id\": 0,\n",
    "                    }\n",
    "                objs.append(obj)\n",
    "                record[\"annotations\"] = objs\n",
    "            dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "DatasetCatalog.register(\"omidb_train\", lambda: get_omidb_dicts(\"/mnt/mia_images/breast/iceberg_selection2\"))\n",
    "MetadataCatalog.get(\"omidb_train\").set(thing_classes=[\"lesion\"])\n",
    "omidb_metadata = MetadataCatalog.get(\"omidb_train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
